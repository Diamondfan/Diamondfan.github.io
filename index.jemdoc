# jemdoc: menu{MENU}{index.html}
= Ruchao Fan

~~~
{}{img_left}{file/rcfan.png}{alt text}{160px}{}
Ruchao Fan, Ph.D. \n
Senior Applied Scientist at Microsoft \n 
Email: fanruchao [at] g [dot] ucla [dot] edu \n
[https://www.linkedin.com/in/ruchao-fan-94271799/ \[LinkedIn\]] [https://github.com/Diamondfan \[Github\]] [https://scholar.google.com/citations?hl=en&authuser=1&user=-Jx0HyYAAAAJ \[Google Scholar\]] \n
Prior Ph.D. Student @[http://www.seas.ucla.edu/spapl/index.html UCLA Speech Processing and Auditory Perception Laboratory] \n
Ph.D. Advisor: [https://www.ee.ucla.edu/abeer-alwan Abeer Alwan] \n
~~~

== Bio 
Ruchao Fan is currently a Senior Applied Scientist at Microsoft Azure AI Speech Team. He obtained his Ph.D. degree from the Department of Electrical and Computer Engineering, UCLA. His research interests are multi-modal representation learning, speech and language modeling, and so on.

During his Ph.D., Rucho Fan worked with [https://www.ee.ucla.edu/abeer-alwan Prof. Abeer Alwan] on speech processing problems. He was focusing on children's speech recognition from a low-resource perspective and end-to-end speech recognition. Prior to that, He received his Master's and Bachelor's degree
from Beijing University of Posts and Telecommunications (BUPT) in 2019 and 2016, respectively.

Ruchao has interned at Sogou Inc. (2018-2019), PAII Inc. (2020), and Microsoft Corporation (2021, 2022), Amazon Web Service (2023), conducting research on speech recognition and language modeling. He was awarded UCLA-Amazon Fellowship during 2021-2022, and was honored as Amazon Fellow. 

== News
- \[Feb 2025\] We released the first Microsoft Multimodal LLM, *Phi-4-MultiModal*!
    -- [https://huggingface.co/microsoft/Phi-4-multimodal-instruct  Phi4-MM Huggingface Weights]
    -- [https://arxiv.org/abs/2503.01743 Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs]
- \[Dec 2024\] Checkout our new Arxiv paper, *AlignFormer*!
    -- When applying the idea of modality matching in speech-LLM, we unlock the zero-shot capability for speech-LLM when training with ASR data only.
    -- [https://arxiv.org/abs/2412.01145 AlignFormer: Modality Matching Can Achieve Better Zero-shot Instruction-Following Speech-LLM] 
- \[Dec 2024\] One co-authored paper was presented at SLT 2024.
    -- The paper talks about how to leaverge extensive text machine translation data for speech translation with modality matching.
    -- [https://arxiv.org/abs/2410.05146 CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation]
- \[Jun 2024\] Check out our paper on bechmarking children's ASR with speech foundation models. The paper was accpeted to Interspeech 2024.
    -- [https://arxiv.org/abs/2406.10507 Benchmarking Children's ASR with Supervised and Self-supervised Speech Foundation Models]
    -- [https://github.com/Diamondfan/SPAPL_KidsASR Code], models are released in [https://github.com/Diamondfan/SPAPL_KidsASR Huggingface]!
- \[May 2024\] I joined Microsoft Azure Speech Team as an Applied Scientist.
- \[Mar 2024\] I successfully defended my Ph.D. thesis and graduated from UCLA. 
    -- [https://escholarship.org/uc/item/9281v84q Improving the Accuracy and Inference Efficiency for Low-resource Automatic Speech Recognition]
- \[Feb 2024\] The Last work for CASS-NAT seris was accepted to IEEE Signal Processing Letters. Check out the paper here.
    -- [https://arxiv.org/abs/2402.08898v1 UniEnc-CASSNAT: An Encoder-only Non-autoregressive ASR for Speech SSL Models]
- \[Jun 2023\] Summer intern at Amazon Web Service, working on long-context large language modeling.
- \[Mar 2023\] My second Journal Paper was accepted to *IEEE Transactions on Audio, Speech,and Language Processing (TASLP)*, and is available for early access:
    --  [https://ieeexplore.ieee.org/abstract/document/10089490 A CTC Alignment-based Non-autoregressive Transformer for End-to-end Automatic Speech Recognition]
    -- Codes for our CASS-NAT work are available at [https://github.com/Diamondfan/cassnat_asr CASS-NAT Code]
- \[Feb 2023\] My summer intern work CTCBERT was accepted to ICASSP 2023!
    -- [https://arxiv.org/abs/2210.08603 CTCBERT: Advancing Hidden-unit BERT with CTC Objectives]
    -- [file/CTCBERT-poster.pdf ICASSP Poster Presentation]
- \[Oct 2022\] My first Journal paper was accpeted to *JSTSP (IEEE Journal of Selected Topics in Signal Processing)*!
    -- [https://ieeexplore.ieee.org/abstract/document/9864219 Towards Better Domain Adaptation for Self-Supervised Models: A Case Study of Child ASR]
    -- [file/JSTSP-SSL-poster.pdf ICASSP Presentation of Journal Papers]
    -- [https://github.com/Diamondfan/fairseq/blob/main/examples/hubert/run_ogi.sh Code for the DRAFT!]
- \[Jun 2022\] A wonderful summer intern @Microsoft, working with Dr. Yiming Wang, Dr. Yashesh Gaur, Dr. Guoli Ye, and Dr. Jinyu Li. This is also my second intern at Microsoft.
- \[Jun 2022\] One paper has been accepted by Interspeech 2022!
    -- [https://arxiv.org/abs/2206.07931 DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children's ASR]
- \[Feb 2022\] I was awarded with [https://www.sciencehub.ucla.edu/2022-amazon-fellows/ UCLA-Amazon Fellowship]! 
- \[Jun 2022\] Two co-authored papers have been accepted by ICASSP 2022!
    -- [https://arxiv.org/abs/2202.12326 Towards Better Meta-Initialization with Task Augmentation for Kindergarten-aged Speech Recognition]
    -- [https://arxiv.org/abs/2202.09529 LPC Augment: An LPC-Based ASR Data Augmentation Algorithm for Low and Zero-Resource Children's Dialects]
- \[Dec 2021\] I passed my Oral Qualifying Exam and became a Ph.D. Candiate.
- \[Dec 2021\] Our journal paper [https://www.sciencedirect.com/science/article/pii/S0167639321000881 Fundamental frequency feature warping for frequency normalization and data augmentation in child automatic speech recognition] has been published on Speech Communication.
- \[Jun 2021\] I started my summer intern @Microsoft, working with [https://scholar.google.com/citations?user=ljFX6R0AAAAJ&hl=en Dr. Guoli Ye] and [https://www.microsoft.com/en-us/research/people/jinyli/ Dr. Jinyu Li].
- \[Jun 2021\] Two papers have been accepted by Interspeech 2021!
    -- [https://arxiv.org/abs/2106.09885 An Improved Single Step Non-autoregressive Transformer for Automatic Speech Recognition]
    -- [https://arxiv.org/abs/2106.09963 Low Resource German ASR with Untranscribed Data Spoken by Non-native Children -- INTERSPEECH 2021 Shared Task SPAPL System]
- \[Jan 2021\] Three papers have been accepted by ICASSP 2021!
    -- [https://arxiv.org/abs/2010.14725 CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer for Speech Recognition] 
    -- [https://arxiv.org/abs/2102.06816 Bi-APC: Bidirectional Autoregressive Predictive Coding for Unsupervised Pre-training and Its Application to Children's ASR]
    -- [https://arxiv.org/abs/2102.09106 Fundamental Frequency Feature Normalization and Data Augmentation for Child Speech Recognition]
- \[Sep 2020\] I had a fruitful summer @PAII, working with [https://scholar.google.com/citations?hl=en&authuser=1&user=IqK3BGYAAAAJ Dr. Wei Chu] and [https://scholar.google.com/citations?hl=en&authuser=1&user=feoBnmkAAAAJ Dr. Peng Chang].
- \[Jul 2020\] Our challenge paper [https://www.isca-speech.org/archive/Interspeech_2020/abstracts/2957.html Exploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification] has been accepted by Interspeech 2020.
- \[Sep 2019\] I started my Ph.D. at UCLA.
- \[Jun 2019\] I got my Master's degree in Beijing University of Posts and Telecommunications.
- \[Jun 2019\] Our Paper [https://www.isca-speech.org/archive/Interspeech_2019/abstracts/2218.html An Online Attention-based Model for Speech Recognition] has been accepted by Interspeech 2019. 


== Peer Review
- Top speech conference and journal
    -- Interspeech, ICASSP
    -- Speech Communication
    -- IEEE Signal Processing Letter
    -- IEEE Journal of Selected Topics in Signal Processing, JSTSP
    -- IEEE Transactionon Audio, Speech, and Language Processing, TASLP
- Others
    -- IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI
    -- NeurIPS 2024, 2025
    -- ICLR 2023, 2024, 2025
    -- IEEE International Conference on Multimedia and Expo, ICME (2021)
    -- Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC (2020, 2021)

== Education 
- Ph.D. University of California, Los Angeles, Los Angeles, CA, U.S.A., Sept. 2019 - Mar. 2024
- M.S. & B.E., Beijing University of Posts and Telecommunications, Beijing, China
    -- M.S., Sept. 2016 - Jun. 2019
    -- B.E., Sept. 2012 - Jun. 2016

